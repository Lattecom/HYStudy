{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create NeuralNetwork Class: Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define NN class\n",
    "class NeuralNetwork(object):\n",
    "    # Initialize NN\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Nodes\n",
    "        self.in_nodes = input_nodes\n",
    "        self.hn_nodes = hidden_nodes\n",
    "        self.ot_nodes = output_nodes\n",
    "        # Learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Weight Matix\n",
    "        ## Weight, input layer to hidden layer\n",
    "        ## np.random.normal(center, standard_deviation, dimension)\n",
    "        self.wih = np.random.normal(0.0, pow(self.hn_nodes, -0.5), (self.hn_nodes, self.in_nodes))\n",
    "        ## Weight, hidden layer to output layer\n",
    "        self.who = np.random.normal(0.0, pow(self.ot_nodes, -0.5), (self.ot_nodes, self.hn_nodes))\n",
    "        \n",
    "        # Activation function\n",
    "        self.activation_function = lambda x: expit(x)\n",
    "        \n",
    "    # Training logic\n",
    "    def train(self, input_list, target_list):\n",
    "        # FeedForward\n",
    "        ## Transform list to 2-dimensional transposed ndarray(to column vector)\n",
    "        inputs = np.array(input_list, ndmin=2).T\n",
    "        targets = np.array(target_list, ndmin=2).T\n",
    "        \n",
    "        ## Operate input signal to hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        ## Operate ouput signal from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        ## Operate hidden signal to output layer\n",
    "        output_inputs = np.dot(self.who, hidden_outputs)\n",
    "        ## Operate output\n",
    "        output_outputs = self.activation_function(output_inputs)\n",
    "        \n",
    "        # Back Propagation\n",
    "        ## Errors\n",
    "        output_errors = targets - output_outputs\n",
    "        ## Hidden layers' errors\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "        \n",
    "        ## Update weight between output and hidden layers\n",
    "        self.who += self.learning_rate * np.dot((output_errors * output_outputs * (1-output_outputs)),\n",
    "                                                np.transpose(hidden_outputs))\n",
    "        ## Update weight between hidden and input layers\n",
    "        self.wih += self.learning_rate * np.dot((hidden_errors * hidden_outputs * (1-hidden_outputs)),\n",
    "                                                np.transpose(inputs))\n",
    "    def query(self, input_list):\n",
    "        # Transform list to 2-dimensional transposed ndarray(to column vector)\n",
    "        inputs = np.array(input_list, ndmin=2).T\n",
    "        # Input to hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # Outputs from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        # Hidden to output layer\n",
    "        output_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # Outputs from output layer\n",
    "        output_outputs = self.activation_function(output_inputs)\n",
    "        return output_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set initial values\n",
    "input_nodes = 3\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3\n",
    "learning_rate = 0.3\n",
    "\n",
    "n = NeuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.56395742],\n",
       "       [ 0.44300005],\n",
       "       [ 0.54129046]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the class\n",
    "n.query([1.2, -0.5, 3.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralNetwork with MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Training dataset\n",
    "with open('./dataframe/[HYStudy 23th] mnist_train_100.csv', 'r') as f:\n",
    "    train_list = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,18,18,18,126,136,175,26,166,255,247,127,0,0,0,0,0,0,0,0,0,0,0,0,30,36,94,154,170,253,253,253,253,253,225,172,253,242,195,64,0,0,0,0,0,0,0,0,0,0,0,49,238,253,253,253,253,253,253,253,253,251,93,82,82,56,39,0,0,0,0,0,0,0,0,0,0,0,0,18,219,253,253,253,253,253,198,182,247,241,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,156,107,253,253,205,11,0,43,154,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,154,253,90,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,139,253,190,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,190,253,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,241,225,160,108,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,240,253,253,119,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,186,253,253,150,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,93,252,253,187,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,249,253,249,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,46,130,183,253,253,207,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,148,229,253,253,253,250,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,114,221,253,253,253,253,201,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,66,213,253,253,253,253,198,81,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,171,219,253,253,253,253,195,80,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,172,226,253,253,253,253,244,133,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,136,253,253,253,212,135,132,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label, 28*28 matrix\n",
    "train_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library to display data\n",
    "import matplotlib.pylab as plt  # to use imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAC1CAYAAABoDoUeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncVqBcDBDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23ff0004b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display data\n",
    "## Create Subplots\n",
    "fig, axes = plt.subplots(2, 5, subplot_kw={\"xticks\": [], \"yticks\": []})\n",
    "\n",
    "# axes.flat: returns the axes as 1-dimensional(flat) array\n",
    "for ax, i in zip(axes.flat, range(0, 10)):\n",
    "    all_values = train_list[i].split(',')\n",
    "    # String to float, all_values[0] = label, trainsform to 28*28 matrix\n",
    "    image_array = np.asfarray(all_values[1:]).reshape(28, 28)\n",
    "    ax.imshow(image_array, cmap=\"Greys\")\n",
    "    ax.set_title(i)\n",
    "fig.subplots_adjust(hspace=-0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEUNJREFUeJzt3X1sXfV9x/H3N4EkYCPIA7uKYkrKgCGUMJdYFKloc9St\n0CAUigYqUiFQVhepewI8CExTojGkCJJ2nZimJcAIrMPj+WlRC43iQYXW5cICCbBAxhIlVh7wklBM\ngIbkuz/uyd21Y997c5/Ocb6fl3Tl8zu/c879+tgfn8frY+6OiMQzIe0CRCQdCr9IUAq/SFAKv0hQ\nCr9IUAq/SFAKv2Bm/Wb2h62eV9Kl8B9HzGyrmf1e2nUcYWZzzOxnZjZoZrqhJGMUfmmmg8DjwE1p\nFyJHU/gDMLOpZvaimX1oZvuS4Y4Rk/2mmf2Hmf3KzJ4zs2kl819sZq+Z2X4ze9PMuqt5X3ff7O4P\nAm838NuRBlH4Y5gA/CNwJvAl4FPg/hHTXA98F5gJfAH8LYCZzQL+FfhrYBrQCzxlZqe3pHJpGoU/\nAHf/X3d/yt0PuPvHwD3A746Y7FF33+TunwB/CVxjZhOB7wBr3H2Nux9295eBPLCgpd+ENNwJaRcg\nzWdmJwM/Ai4DpiajTzGzie5+KGlvL5llG3AiMIPC3sLVZnZFSf+JwLrmVi3NpvDHcBvwW8BX3X2X\nmXUC/wlYyTRnlAx/icLJukEKfxQedffvtapYaQ3t9h9/TjSzKSWvE4BTKBzn709O5C0ZZb7vmNn5\nyV7CXwFPJnsF/wRcYWaXmtnEZJndo5wwPIoVTAEmJe0pZja5Ud+o1EfhP/6soRD0I6+lwN8AJ1HY\nkv878NNR5nsUeBjYBUwB/gTA3bcDC4G7gA8p7An8OdX97pyZ1HDkbP+nwOZj/o6kKUz/zEMkJm35\nRYJS+EWCUvhFglL4RYJq6XX+GTNm+OzZs4vtTz75hLa2tlaWULWs1pbVukC11aqRtW3dupXBwUGr\nPCXg7jW/KNwxthnYAiyuNP28efO81Lp16zyrslpbVutyV221amRtScaqym/Nu/3Jfd9/B3wTOB+4\n1szOr3V5ItJa9RzzXwRscfcP3P3XQB+Fm0FEZByo55h/FsM/DLID+OrIicysB+gByOVy9Pf3F/uG\nhoaGtbMkq7VltS5QbbVKrbZqjw9GvoA/AB4oaV8H3F9uHh3z1y+rdbmrtlqNu2N+YIDhnwTrSMaJ\nyDhQT/jXA+eY2ZfNbBLwbeD5xpQlIs1W8zG/u39hZn8E/AyYCDzk7vpfbSLjRF03+bj7GgofIRWR\ncUa394oEpfCLBKXwiwSl8IsEpfCLBKXwiwSl8IsEpfCLBKXwiwSl8IsEpfCLBKXwiwSl8IsEpfCL\nBKXwiwSl8IsEpfCLBKXwiwSl8IsEpfCLBKXwiwSl8IsEpfCLBKXwiwSl8IsEpfCLBKXwiwSl8IsE\npfCLBFXXU3pFmmnVqlVl+2+++eay/YcPHy4OL1++nPnz5xfbmzdvLjvvueeeW0WF41td4TezrcDH\nwCHgC3fvakRRItJ8jdjyz3f3wQYsR0RaSMf8IkGZu9c+s9n/AB9R2O3/B3dfOco0PUAPQC6Xm9fX\n11fsGxoaor29veb3b6as1pbVuqDxtQ0Olt+h3LZtW9XL6ujoYMeOHcX2nDlzyk4/efLkqpddr0au\nt97eXvL5vFUzbb27/Ze4+4CZ/Qbwspn9l7u/UjpB8gdhJUBXV5d3d3cX+/r7+yltZ0lWa8tqXdD4\n2iqd8Lv99tvL9o884dfb21tsZ+mEX1o/07p2+919IPm6B3gGuKgRRYlI89UcfjNrM7NTjgwD3wA2\nNaowEWmuenb7c8AzZnZkOf/s7j9tSFUSwtq1a8v233rrrWX7J0w4tm1X6fTJ721oNYff3T8AfruB\ntYhIC+lSn0hQCr9IUAq/SFAKv0hQCr9IUPpIr6TmvffeK9v/2WeftaiSmLTlFwlK4RcJSuEXCUrh\nFwlK4RcJSuEXCUrhFwlK1/mlqd55550x+5YuXVrXsi+88MKy/S+99FJxOJ/Ps3fv3mK7ra2trvc+\nHmjLLxKUwi8SlMIvEpTCLxKUwi8SlMIvEpTCLxKUrvNLXbZs2VIc/vzzz4e1ARYsWDDmvKXX3Wux\nbNmysv2nnnpqcXjixInD2qItv0hYCr9IUAq/SFAKv0hQCr9IUAq/SFAKv0hQus4vdXnggQeKw3Pn\nzmXdunXD+rdv317zsq+66qqy/fPnz6952VLFlt/MHjKzPWa2qWTcNDN72czeT75ObW6ZItJo1ez2\nPwxcNmLcYmCtu58DrE3aIjKOVAy/u78CjLwPcyGwOhleDVzZ4LpEpMnM3StPZDYbeNHd5yTt/e5+\nWjJswL4j7VHm7QF6AHK53Ly+vr5i39DQEO3t7XV+C82R1dqyVtfAwEBx+KSTTuLTTz8d1r9r166a\nlz11avmjybPOOqvqZWVtvZVqZG29vb3k83mrZtq6T/i5u5vZmH9B3H0lsBKgq6vLu7u7i339/f2U\ntrMkq7Vlra7Fi///iG/u3Lls3LhxWP99991X87IrnfB74oknql5W1tZbqbRqq/VS324zmwmQfN3T\nuJJEpBVqDf/zwKJkeBHwXGPKEZFWqbjbb2aPAd3ADDPbASwBlgGPm9lNwDbgmmYWKek5cOBA2f7S\n3fp77733qN38CRPG3r5Mnz697LLvvvvuKiqUWlUMv7tfO0bX1xtci4i0kG7vFQlK4RcJSuEXCUrh\nFwlK4RcJSh/pDW7//v1l+xcuXNi09670iO7zzjuvae8t2vKLhKXwiwSl8IsEpfCLBKXwiwSl8IsE\npfCLBKXr/MG9+uqrZftfe+21upZ/9dVXj9l3ww031LVsqY+2/CJBKfwiQSn8IkEp/CJBKfwiQSn8\nIkEp/CJB6Tr/cW79+vVl+xctWlS2v5IrrriiOHzaaacNawOsWrVqzHmnTJlS13tLfbTlFwlK4RcJ\nSuEXCUrhFwlK4RcJSuEXCUrhFwlK1/mPA+X+9/7FF1/c1Pc+++yzi8OTJ08e1gZoa2tr6vtL7Spu\n+c3sITPbY2abSsYtNbMBM9uQvBY0t0wRabRqdvsfBi4bZfyP3L0zea1pbFki0mwVw+/urwB7W1CL\niLSQuXvlicxmAy+6+5ykvRS4EfgIyAO3ufu+MebtAXoAcrncvL6+vmLf0NAQ7e3tdX0DzZLV2kar\n69ChQ2NOv2HDhqbWk8vlisMnn3wyBw4cGNbf0dHR1PevVlZ/ntDY2np7e8nn81bNtLWGPwcMAg7c\nDcx09+9WWk5XV5fn8/liu7+/n+7u7mrqbLms1jZaXeVO+E2fPr2p9dxyyy3F4c7OzqP+2Cxfvryp\n71+trP48obG1dXV1VR3+mi71uftudz/k7oeBVcBFtSxHRNJTU/jNbGZJ81vAprGmFZFsqnid38we\nA7qBGWa2A1gCdJtZJ4Xd/q3A95tYo1SwYsWKMfsmTGjufVx33HFHcfjNN98c1pZsqxh+d792lNEP\nNqEWEWkh3d4rEpTCLxKUwi8SlMIvEpTCLxKUPtI7DgwMDBSHDx48OKwN8OSTTzbtvW+88cay/aef\nfnpx+IQTThjWlmzTll8kKIVfJCiFXyQohV8kKIVfJCiFXyQohV8kKF3nHwe6urqKw3feeSfXX3/9\nsP7BwcGal33ppZeW7b///vtrXrZkm7b8IkEp/CJBKfwiQSn8IkEp/CJBKfwiQSn8IkHpOv84sGfP\nnuLwwYMHh7Whvn/PXelfbU+aNKnmZUu2acsvEpTCLxKUwi8SlMIvEpTCLxKUwi8SlMIvElQ1j+g+\nA3gEyFF4JPdKd/+xmU0D/gWYTeEx3de4+77mlXr86u3tLdt/+PDhsu16XHDBBQ1blowv1Wz5vwBu\nc/fzgYuBH5jZ+cBiYK27nwOsTdoiMk5UDL+773T3N5Lhj4F3gVnAQmB1Mtlq4MpmFSkijXdMx/xm\nNhv4CvBLIOfuO5OuXRQOC0RknDB3r25Cs3bg34B73P1pM9vv7qeV9O9z96mjzNcD9ADkcrl5fX19\nxb6hoSHa29vr/Baao5W17dixo2z/7t27i8MdHR0Vpz8WnZ2dZfsnTpxY9bL086xNI2vr7e0ln89b\nNdNW9cEeMzsReAr4ibs/nYzebWYz3X2nmc0E9ow2r7uvBFYCdHV1eXd3d7Gvv7+f0naWtLK2Sif8\nVqxYURxevnz5UdPX88GevXv3lu0/9dRTq16Wfp61Sau2ir81ZmbAg8C77v7Dkq7ngUXJ8CLgucaX\nJyLNUs2W/2vAdcBGM9uQjLsLWAY8bmY3AduAa5pT4vg38pHaI1V6xPbILfvI9uTJk8ecd8mSJWWX\n3dbWVrZfjl8Vw+/uvwDGOob4emPLEZFW0R1+IkEp/CJBKfwiQSn8IkEp/CJBKfwiQelfd7fA0NBQ\n2f5K9wFUMnv27DH7Kv1rbolLW36RoBR+kaAUfpGgFH6RoBR+kaAUfpGgFH6RoBR+kaAUfpGgFH6R\noBR+kaAUfpGgFH6RoBR+kaAUfpGg9Hn+Fpg1a1bZ/ssvv7xs/wsvvNDIckQAbflFwlL4RYJS+EWC\nUvhFglL4RYJS+EWCUvhFgqp4nd/MzgAeAXKAAyvd/cdmthT4HvBhMuld7r6mWYWOZ+3t7WX7n332\n2aqX1d/fz6FDh+otSaSqm3y+AG5z9zfM7BTgdTN7Oen7kbsvb155ItIsFcPv7juBncnwx2b2LlD+\nljURyTxz9+onNpsNvALMAW4FbgQ+AvIU9g72jTJPD9ADkMvl5vX19RX7hoaGKu4SpyWrtWW1LlBt\ntWpkbb29veTzeatqYnev6gW0A68DVyXtHDCRwknDe4CHKi1j3rx5XmrdunWeVVmtLat1uau2WjWy\ntiRjVWW6qrP9ZnYi8BTwE3d/OvmjsdvdD7n7YWAVcNEx/YkSkVRVDL+ZGfAg8K67/7Bk/MySyb4F\nbGp8eSLSLNWc7f8acB2w0cw2JOPuAq41s04Kl/+2At9vSoUi0hTVnO3/BTDaCQRd0xcZx3SHn0hQ\nCr9IUAq/SFAKv0hQCr9IUAq/SFAKv0hQCr9IUAq/SFAKv0hQCr9IUAq/SFAKv0hQCr9IUMf0P/zq\nfjOzD4FtJaNmAIMtK+DYZLW2rNYFqq1WjaztTHc/vZoJWxr+o97cLO/uXakVUEZWa8tqXaDaapVW\nbdrtFwlK4RcJKu3wr0z5/cvJam1ZrQtUW61SqS3VY34RSU/aW34RSYnCLxJUKuE3s8vMbLOZbTGz\nxWnUMBYz22pmG81sg5nlU67lITPbY2abSsZNM7OXzez95OvUDNW21MwGknW3wcwWpFTbGWa2zsze\nMbO3zexPk/GprrsydaWy3lp+zG9mE4H3gN8HdgDrgWvd/Z2WFjIGM9sKdLl76jeEmNnvAEPAI+4+\nJxl3L7DX3ZclfzinuvsdGaltKTDkKT+2PXma1Ewveaw8cCVwAymuuzJ1XUMK6y2NLf9FwBZ3/8Dd\nfw30AQtTqCPz3P0VYO+I0QuB1cnwagq/PC03Rm2Z4O473f2NZPhj4Mhj5VNdd2XqSkUa4Z8FbC9p\n7yDFFTAKB35uZq8njxfPmpy770yGd1F4WnKW/LGZvZUcFqRySFIqeaz8V4BfkqF1N6IuSGG96YTf\n0S5x907gm8APkt3bTPLCMVuWrtX+PXAW0AnsBFakWYyZtVN4uvSfufuvSvvSXHej1JXKeksj/APA\nGSXtjmRcJrj7QPJ1D/AM2Xv0+O4jT0hOvu5JuZ6iLD22fbTHypOBdZelx92nEf71wDlm9mUzmwR8\nG3g+hTqOYmZtyYkYzKwN+AbZe/T488CiZHgR8FyKtQyTlce2j/VYeVJed5l73L27t/wFLKBwxv+/\ngb9Io4Yx6joLeDN5vZ12bcBjFHYDD1I4N3ITMB1YC7wP/ByYlqHaHgU2Am9RCNrMlGq7hMIu/VvA\nhuS1IO11V6auVNabbu8VCUon/ESCUvhFglL4RYJS+EWCUvhFglL4RYJS+EWC+j9cD9BCZ32tkwAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23ff0004c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,124,253,255,63,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,96,244,251,253,62,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,127,251,251,253,62,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,68,236,251,211,31,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,60,228,251,251,94,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,155,253,253,189,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,253,251,235,66,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,32,205,253,251,126,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,104,251,253,184,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,240,251,193,23,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,32,253,253,253,159,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,151,251,251,251,39,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,48,221,251,251,172,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,234,251,251,196,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,253,251,251,89,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,159,255,253,253,31,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,48,228,253,247,140,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,251,253,220,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,251,253,220,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,193,253,220,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display \"1\"(with grid)\n",
    "all_values = train_list[3].split(',')\n",
    "# String to float, all_values[0] = label, transform to 28*28 matrix\n",
    "image_array = np.asfarray(all_values[1:]).reshape(28, 28)\n",
    "\n",
    "# Draw image\n",
    "plt.imshow(image_array, cmap=\"Greys\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Label {}\".format(all_values[0]))\n",
    "plt.show()\n",
    "\n",
    "train_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.49141176  0.99223529\n",
      "  1.          0.25458824  0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.38270588  0.95729412\n",
      "  0.98447059  0.99223529  0.25070588  0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.50305882\n",
      "  0.98447059  0.98447059  0.99223529  0.25070588  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.274\n",
      "  0.92623529  0.98447059  0.82917647  0.13035294  0.04105882  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.24294118\n",
      "  0.89517647  0.98447059  0.98447059  0.37494118  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.61176471  0.99223529  0.99223529  0.74376471  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.08764706  0.99223529  0.98447059  0.92235294  0.26623529  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.13423529  0.80588235  0.99223529  0.98447059  0.49917647  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.41376471  0.98447059  0.99223529  0.72435294  0.06823529  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.32058824  0.94176471  0.98447059  0.75929412  0.09929412  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.13423529  0.99223529  0.99223529  0.99223529  0.62729412  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.59623529  0.98447059  0.98447059  0.98447059  0.16141176  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.19635294  0.868       0.98447059  0.98447059  0.67776471  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.91847059  0.98447059  0.98447059  0.77094118  0.05658824  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.99223529  0.98447059  0.98447059  0.35552941  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.62729412  1.          0.99223529  0.99223529  0.13035294  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.19635294  0.89517647  0.99223529  0.96894118  0.55352941  0.04105882\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.25847059  0.98447059  0.99223529  0.86411765  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.25847059  0.98447059  0.99223529  0.86411765  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.10317647  0.75929412  0.99223529  0.86411765  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01      ]\n"
     ]
    }
   ],
   "source": [
    "# Normalize RGB values\n",
    "# +0.01 to prevent '0' as output\n",
    "# '0' input makes activation function's output to '0'\n",
    "norm_input = (np.asfarray(all_values[1:]) / 255 * 0.99) + 0.01\n",
    "print(norm_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01,  0.99,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create output label array to put in NN\n",
    "# Range must be 0 < X < 1 (Sigmoid)\n",
    "out_nodes = 10\n",
    "\n",
    "# Target value(label)\n",
    "# 1 -> 0.99, 0 -> 0.01 to satisfy constraint\n",
    "targets = np.zeros(out_nodes) + 0.01\n",
    "# all_values[0] = label\n",
    "targets[int(all_values[0])] = 0.99\n",
    "\n",
    "# label = 1(index[1] = 0.99)\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define network structure\n",
    "input_nodes = 784  # Data = 28*28\n",
    "\n",
    "# The number of hidden nodes: choose heuristically\n",
    "# Must be smaller than input nodes to extract core feature\n",
    "# Properly larger than output nodes\n",
    "hidden_nodes = 100\n",
    "\n",
    "# The number of output nodes: same as the number of labels\n",
    "output_nodes = 10\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.3\n",
    "\n",
    "# Create instance of NN\n",
    "n = NeuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the NN\n",
    "for record in train_list:\n",
    "    # Split the csv data by seperator ','\n",
    "    all_values = record.split(',')\n",
    "    # Normalize input values\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255 * 0.99) + 0.01\n",
    "    # Create target value\n",
    "    targets = np.zeros(output_nodes) + 0.01\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    n.train(inputs, targets)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "with open('./dataframe/[HYStudy 23th] mnist_test_10.csv', 'r') as f:\n",
    "    test_list = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer is 7\n"
     ]
    }
   ],
   "source": [
    "# Test 1st data\n",
    "test_values = test_list[0].split(',')\n",
    "print(\"Correct answer is\", test_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01994044]\n",
      " [ 0.00331181]\n",
      " [ 0.02346481]\n",
      " [ 0.00552693]\n",
      " [ 0.00213431]\n",
      " [ 0.02977635]\n",
      " [ 0.00120625]\n",
      " [ 0.97150379]\n",
      " [ 0.00624988]\n",
      " [ 0.02218302]]\n",
      "Maximum value is [ 0.97150379] and index is 7\n",
      "Predicted label is 7\n"
     ]
    }
   ],
   "source": [
    "# Send query with nomalized value\n",
    "ans = n.query((np.asfarray(test_values[1:]) / 255.0 * 0.99) + 0.01)\n",
    "print(ans)\n",
    "print(\"Maximum value is {} and index is {}\".format(max(ans), np.argmax(ans)))\n",
    "print(\"Predicted label is\", np.argmax(ans))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
